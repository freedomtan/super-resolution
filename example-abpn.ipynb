{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from data import DIV2K\n",
    "from model.abpn import abpn\n",
    "from train import AbpnTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-resolution factor\n",
    "scale = 2\n",
    "\n",
    "# Downgrade operator\n",
    "downgrade = 'bicubic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of model weights (needed for demo)\n",
    "weights_dir = f'weights/abpn-x{scale}'\n",
    "weights_file = os.path.join(weights_dir, 'weights.h5')\n",
    "\n",
    "os.makedirs(weights_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "You don't need to download the DIV2K dataset as the required parts are automatically downloaded by the `DIV2K` class. By default, DIV2K images are stored in folder `.div2k` in the project's root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div2k_train = DIV2K(scale=scale, subset='train', downgrade=downgrade)\n",
    "div2k_valid = DIV2K(scale=scale, subset='valid', downgrade=downgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = div2k_train.dataset(batch_size=16, random_transform=True)\n",
    "valid_ds = div2k_valid.dataset(batch_size=1, random_transform=False, repeat_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Pre-trained models\n",
    "\n",
    "If you want to skip training and directly run the demo below, download [weights-abpn-x2.tar.gz](https://github.com/freedomtan/some_super_resolution_tflite_models/blob/main/h5_weights/weights-abpn-x2.tar.gz?raw=true) and extract the archive in the project's root directory. This will create a `weights/abpn-x2` directory containing the weights of the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AbpnTrainer(model=abpn(scale=scale), \n",
    "                      checkpoint_dir=f'.ckpt/abpn-x{scale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train ABPN model for 300,000 steps and evaluate model\n",
    "# every 1000 steps on the first 10 images of the DIV2K\n",
    "# validation set. Save a checkpoint only if evaluation\n",
    "# PSNR has improved.\n",
    "trainer.train(train_ds,\n",
    "              valid_ds.take(10),\n",
    "              steps=300000, \n",
    "              evaluate_every=1000, \n",
    "              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore from checkpoint with highest PSNR\n",
    "trainer.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on full validation set\n",
    "psnrv = trainer.evaluate(valid_ds)\n",
    "print(f'PSNR = {psnrv.numpy():3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to separate location (needed for demo)\n",
    "trainer.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = abpn(scale=scale)\n",
    "model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import resolve_single\n",
    "from utils import load_image, plot_sample\n",
    "\n",
    "def resolve_and_plot(lr_image_path):\n",
    "    lr = load_image(lr_image_path)\n",
    "    sr = resolve_single(model, lr)\n",
    "    plot_sample(lr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot('demo/0869x4-crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot('demo/0829x4-crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot('demo/0851x4-crop.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
